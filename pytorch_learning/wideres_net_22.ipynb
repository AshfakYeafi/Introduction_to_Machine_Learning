{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bae2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv_2d(ni, nf, stride=1, ks=3):\n",
    "    return nn.Conv2d(in_channels=ni, out_channels=nf, \n",
    "                     kernel_size=ks, stride=stride, \n",
    "                     padding=ks//2, bias=False)\n",
    "\n",
    "def bn_relu_conv(ni, nf):\n",
    "    return nn.Sequential(nn.BatchNorm2d(ni), \n",
    "                         nn.ReLU(inplace=True), \n",
    "                         conv_2d(ni, nf))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(ni)\n",
    "        self.conv1 = conv_2d(ni, nf, stride)\n",
    "        self.conv2 = bn_relu_conv(nf, nf)\n",
    "        self.shortcut = lambda x: x\n",
    "        if ni != nf:\n",
    "            self.shortcut = conv_2d(ni, nf, stride, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(x), inplace=True)\n",
    "        r = self.shortcut(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) * 0.2\n",
    "        return x.add_(r)\n",
    "\n",
    "def make_group(N, ni, nf, stride):\n",
    "    start = ResidualBlock(ni, nf, stride)\n",
    "    rest = [ResidualBlock(nf, nf) for j in range(1, N)]\n",
    "    return [start] + rest\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, n_groups, N, n_classes, k=1, n_start=16):\n",
    "        super().__init__()      \n",
    "        # Increase channels to n_start using conv layer\n",
    "        layers = [conv_2d(3, n_start)]\n",
    "        n_channels = [n_start]\n",
    "        \n",
    "        # Add groups of BasicBlock(increase channels & downsample)\n",
    "        for i in range(n_groups):\n",
    "            n_channels.append(n_start*(2**i)*k)\n",
    "            stride = 2 if i>0 else 1\n",
    "            layers += make_group(N, n_channels[i], \n",
    "                                 n_channels[i+1], stride)\n",
    "        \n",
    "        # Pool, flatten & add linear layer for classification\n",
    "        layers += [nn.BatchNorm2d(n_channels[3]), \n",
    "                   nn.ReLU(inplace=True), \n",
    "                   nn.AdaptiveAvgPool2d(1), \n",
    "                   Flatten(), \n",
    "                   nn.Linear(n_channels[3], n_classes)]\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)\n",
    "    \n",
    "def wrn_22(): \n",
    "    return WideResNet(n_groups=3, N=3, n_classes=10, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28c4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=wrn_22()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df88601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideResNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ResidualBlock(\n",
       "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(192, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9): ResidualBlock(\n",
       "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): AdaptiveAvgPool2d(output_size=1)\n",
       "    (13): Flatten()\n",
       "    (14): Linear(in_features=384, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252d09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
